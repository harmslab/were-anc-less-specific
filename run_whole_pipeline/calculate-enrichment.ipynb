{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import hops_enrich\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate clusters of all sequences seen in the hA5, hA6, ancA5/A6, and altAll samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Go through all-pooled counts files\n",
    "for all_seq_file in glob.glob(\"*_all_pooled.counts\"):\n",
    "\n",
    "    # Get list of all sequences seen in these files\n",
    "    seq_list = []\n",
    "    with open(all_seq_file) as f:\n",
    "        for line in f:\n",
    "            seq_list.append(line.split()[0].strip())\n",
    "    \n",
    "    \n",
    "    # Generate clusters\n",
    "    cluster_file = f\"{all_seq_file.split('.counts')[0]}.cluster\"\n",
    "    hops_enrich.cluster.cluster_seqs(seq_list,\n",
    "                                     epsilon=1,\n",
    "                                     min_neighbors=1,\n",
    "                                     dist_function=\"simple\",\n",
    "                                     out_file=cluster_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_enrichment(conv_file,comp_file,cluster_file,out_file=None,min_counts=6):\n",
    "\n",
    "    conv = hops_enrich.enrich.load_counts_file(conv_file)\n",
    "    comp = hops_enrich.enrich.load_counts_file(comp_file)\n",
    "    clusters, _ = hops_enrich.cluster.read_cluster_file(cluster_file)\n",
    "    enrichment, _, _, gaussian_stats = hops_enrich.enrich.calc_enrichment(conv,comp,clusters,min_counts=min_counts,out_file=out_file)\n",
    "    \n",
    "    unresponsive_mean = np.max(gaussian_stats[0])\n",
    "    \n",
    "    for k in enrichment:\n",
    "        enrichment[k] = enrichment[k] - unresponsive_mean\n",
    "        \n",
    "    return enrichment\n",
    "\n",
    "\n",
    "enrichment = {}\n",
    "for sample in [\"hA5\",\"hA6\",\"aA5A6\",\"alt\"]:\n",
    "    for x in [\"1\",\"2\",\"pooled\"]:\n",
    "    \n",
    "        print(sample,x)\n",
    "    \n",
    "        key = f\"{sample}_{x}\"\n",
    "    \n",
    "        enrichment[key] = get_enrichment(f\"../enrichment_files/{sample}_conv_{x}.counts\",\n",
    "                                         f\"../enrichment_files/{sample}_comp_{x}.counts\",\n",
    "                                         f\"../enrichment_files/{sample}_all_pooled.cluster\",\n",
    "                                         out_file=f\"{sample}_{x}.enrich\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_df(enrich,names):\n",
    "    \n",
    "    sets = []\n",
    "    for e in enrich:\n",
    "        sets.append(set(e.keys()))\n",
    "    \n",
    "    shared_seq = sets[0]\n",
    "    for s in sets[1:]:\n",
    "        shared_seq = shared_seq.intersection(s)\n",
    "        \n",
    "    out_dict = {\"seq\":[]}\n",
    "    for n in names:\n",
    "        out_dict[n] = []\n",
    "    for seq in shared_seq:\n",
    "        out_dict[\"seq\"].append(seq)\n",
    "        for i, e in enumerate(enrich):\n",
    "            out_dict[names[i]].append(e[seq])\n",
    "        \n",
    "    return pd.DataFrame(out_dict)\n",
    "\n",
    "aA5A6_df = build_df([enrichment[\"hA5_pooled\"],enrichment[\"hA6_pooled\"],enrichment[\"aA5A6_pooled\"]],\n",
    "                    [\"hA5\",\"hA6\",\"aA5A6\"])\n",
    "aA5A6_df.to_csv(\"hA5-hA6-aA5A6_enrichment.txt\")\n",
    "\n",
    "alt_df = build_df([enrichment[\"hA5_pooled\"],enrichment[\"hA6_pooled\"],enrichment[\"alt_pooled\"]],\n",
    "                    [\"hA5\",\"hA6\",\"alt\"])\n",
    "alt_df.to_csv(\"hA5-hA6-alt_enrichment.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anisotropy_peptides = {\"phage_ctl_0\":\"EGLDLMSILELI\",\n",
    "                       \"phage_ctl_1\":\"RHGFLQDILFKL\",\n",
    "                       \"phage_ctl_2\":\"GWLEQYFSRTAD\",\n",
    "                       \"phage_ctl_4\":\"SRQTTSTHEWVV\",\n",
    "                       \"phage_ctl_5\":\"EQPLLKYLQLMR\",\n",
    "                       \"phage_ctl_6\":\"HVQWRDRNVIEW\",\n",
    "                       \"phage_ctl_7\":\"GEVTNYGYLVDQ\",\n",
    "                       \"phage_ctl_8\":\"SSSTYPGFRQST\",\n",
    "                       \"phage_ctl_9\":\"SGPSDWLHKGVL\"}\n",
    "\n",
    "mask = [s in anisotropy_peptides.values() for s in aA5A6_df.seq]\n",
    "aA5A6_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = build_df([enrichment[\"hA5_pooled\"],enrichment[\"hA6_pooled\"],enrichment[\"aA5A6_pooled\"],enrichment[\"alt_pooled\"]],\n",
    "                    [\"hA5\",\"hA6\",\"aA5A6\",\"alt\"])\n",
    "all_df.to_csv(\"hA5-hA6-aA5A6-alt_enrichment.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
